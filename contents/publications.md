#### Published

- <strong>Miaozeng Du</strong>, Jiaqi Li*, Sirui Pan, Yi Zhan, Guilin Qi, Yuxin Zhang, Rihui Jin, Yinjia Shu, Qianshan Wei (2025).
Forget What Has Seen: Selective Concept Unlearning in Segmentation Foundation Models. <strong>AAAI 2026</strong>. 

- Jiaqi Li, <strong>Miaozeng Du*</strong>, Chuanyi Zhang, Yongrui Chen, Nan Hu, Guilin Qi, Haiyun Jiang, Siyuan Cheng, Bozhong Tian (2024).
  MIKE: A New Benchmark for Fine-grained Multimodal Entity Knowledge Editing. <strong>ACL 2024 Findings</strong>. [[Paper]](https://aclanthology.org/2024.findings-acl.298/)

- Jiaqi Li, Chuanyi Zhang, <strong>Miaozeng Du</strong>, Hui Zhang, Yongrui Chen, Qianshan Wei, Junfeng Fang, Ruipeng Wang, Sheng Bi, Guilin Qi (2025). Forget the Token and Pixel: Rethinking Gradient Ascent for Concept Unlearning in Multimodal Generative Models. <strong>ACL 2025 Findings</strong>. [[Paper]](https://aclanthology.org/2025.findings-acl.630/)

- Jiaqi Li, Chuanyi Zhang, <strong>Miaozeng Du</strong>, Dehai Min, Yongrui Chen, Guilin Qi (2023). Three Stream Based Multi-level Event Contrastive Learning for Text-Video Event Extraction. <strong>EMNLP 2023 Main</strong>. [[Paper]](https://aclanthology.org/2023.emnlp-main.103/)

- Jiaqi Li, Qianshan Wei, Chuanyi Zhang, Guilin Qi, <strong>Miaozeng Du</strong>, Yongrui Chen, Sheng Bi, Fan Liu (2024). Single Image Unlearning: Efficient Machine Unlearning in Multimodal Large Language Models. <strong>NeurIPS 2024</strong>. [[Paper]](https://proceedings.neurips.cc/paper_files/paper/2024/file/3e53d82a1113e3d240059a9195668edc-Paper-Conference.pdf)

\* means Co-first author.





